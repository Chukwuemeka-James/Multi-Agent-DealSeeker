{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5597f8f",
   "metadata": {},
   "source": [
    "### **Introduction to the Price Estimation Notebook**\n",
    "\n",
    "This Jupyter Notebook demonstrates an AI-powered approach to estimating product prices using retrieval-augmented generation (RAG) with a combination of **sentence embeddings, a vector database, OpenAI's GPT-4o-mini model and DeepSeek's model**. The goal is to predict the price of an item by leveraging similar products stored in a vector database.\n",
    "\n",
    "### **Notebook Workflow**\n",
    "1. **Setup and Dependencies**  \n",
    "2. **Loading and Processing Data**\n",
    "3. **Vector Search for Similar Products**\n",
    "4. **GPT-4o-mini Model for Price Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from utils.items import Item\n",
    "from utils.testing import Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2caed1",
   "metadata": {},
   "source": [
    "### **Evironment setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77690031",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acc8b9",
   "metadata": {},
   "source": [
    "### **Load in the test pickle file for evaluation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf28d3d",
   "metadata": {},
   "source": [
    "### **Create the make_context function:** \n",
    "- This function helps in constructing the context (message) that will be provided to the frontier model for price estimation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context(similars, prices):\n",
    "    message = \"To provide some context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(similars, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f2871",
   "metadata": {},
   "source": [
    "**The above function `make_context` creates a message with the context of similar items and their prices. It helps in constructing the context that will be provided to the GPT model for price estimation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(item, similars, prices):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = make_context(similars, prices)\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d543aa",
   "metadata": {},
   "source": [
    "**The above function prepares the messages to send to the frontier model. Includes a system message, user prompt with item context, and an assistant message template.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929dd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = \"products_vectorstore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and create a persistent client for the Chroma DB.\n",
    "\n",
    "client = chromadb.PersistentClient(path=DB)\n",
    "collection = client.get_or_create_collection('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(item):\n",
    "    text = item.prompt.replace(\"How much does this cost to the nearest dollar?\\n\\n\", \"\")\n",
    "    return text.split(\"\\n\\nPrice is $\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144edaa6",
   "metadata": {},
   "source": [
    "**The `description` function extracts the description of an item for price estimation. It cleans up the input text to only include relevant details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "description(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e55da8",
   "metadata": {},
   "source": [
    "### **Get vector representaion of items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(item):\n",
    "    return model.encode([description(item)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ca794",
   "metadata": {},
   "source": [
    "**The `vector` function gets the vector representation of an item using a sentence transformer model. This will be used for querying similar items in the vector store.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars(item):\n",
    "    results = collection.query(query_embeddings=vector(item).astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "    return documents, prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577efbb7",
   "metadata": {},
   "source": [
    "**The above function `(find_similars)`, finds the top 5 most similar items from the vector store using the encoded vector of the item. it returns both the descriptions and the corresponding prices of the similar items.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b873cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[1].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, prices = find_similars(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_context(documents, prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce119cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages_for(test[1], documents, prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960004a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3105f",
   "metadata": {},
   "source": [
    "**The above function extracts the actual price from a formatted string (e.g., \"$99.99\"). This function handles various price formats and returns a float value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd19c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_4o_mini_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=messages_for(item, documents, prices),\n",
    "        seed=42,\n",
    "        max_tokens=5\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b4d376",
   "metadata": {},
   "source": [
    "**The above function uses the GPT-4o-mini model to estimate the price of an item based on similar items. It returns the price predicted by the model for the item in question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function with a sample item.\n",
    "\n",
    "gpt_4o_mini_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a428600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual price for comparison.\n",
    "\n",
    "test[1].price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e68979",
   "metadata": {},
   "source": [
    "### **Test the model performance on a set of test data using the Tester class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(gpt_4o_mini_rag, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e245f",
   "metadata": {},
   "source": [
    "###  **DeepSeek's API call implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DeepSeek using the OpenAI client python library\n",
    "\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "deepseek_via_openai_client = OpenAI(api_key=deepseek_api_key,base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12636263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added some retry logic here because DeepSeek is very oversubscribed and sometimes fails..\n",
    "\n",
    "def deepseek_api_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    retries = 8\n",
    "    done = False\n",
    "    while not done and retries > 0:\n",
    "        try:\n",
    "            response = deepseek_via_openai_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\", \n",
    "                messages=messages_for(item, documents, prices),\n",
    "                seed=42,\n",
    "                max_tokens=8\n",
    "            )\n",
    "            reply = response.choices[0].message.content\n",
    "            done = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retries -= 1\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2814683",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(deepseek_api_rag, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb909dd9",
   "metadata": {},
   "source": [
    "### **Let's wrap it into the agent class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ensemble_Agent.frontier_agent import FrontierAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the logs so we can see what's going on\n",
    "\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FrontierAgent(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b22d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.price(\"Quadcast HyperX condenser mic for high quality podcasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae11f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ensemble_Agent.specialist_agent import SpecialistAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = SpecialistAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2.price(\"Quadcast HyperX condenser mic for high quality podcasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4ad9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
