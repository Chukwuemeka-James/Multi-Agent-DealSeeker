{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Big Project Begins: Data Curation for Large Language Models (LLMs) - Part 1**  \n",
    "\n",
    "Welcome to the first part of our journey into **data curation for LLM training**! In this session, we will explore how to **scrub, filter, and structure data** for a machine-learning model that estimates product prices based on textual descriptions.  \n",
    "\n",
    "### **Key Learning Objectives**\n",
    "By the end of this lecture, you will:\n",
    "- Understand the **importance of data curation** in machine learning  \n",
    "- Learn how to **load and preprocess datasets** from Hugging Face  \n",
    "- Explore **dataset statistics and distributions** using Python  \n",
    "- Learn how to **format data into training-friendly prompts**  \n",
    "- Understand **tokenization constraints** and their impact on model training  \n",
    "\n",
    "### **Problem Statement: The Product Pricer**  \n",
    "The goal of this project is to build an **AI model** that can estimate **how much a product costs based on its description**. To do this, we need to **curate a high-quality dataset** that contains product descriptions and their corresponding prices.  \n",
    "\n",
    "For this lecture, we will **focus on home appliances**, using the **Amazon Reviews 2023** dataset from Hugging Face.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset Information**\n",
    "We will be using a publicly available dataset:  \n",
    "ðŸ”— **Dataset:** [Amazon Reviews 2023](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023)  \n",
    "ðŸ”— **Product Metadata Folder:** [Meta Categories](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories)  \n",
    "\n",
    "This dataset contains **metadata for various product categories**, including their **titles, descriptions, features, details, and prices**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "\n",
    "# Check if API keys are properly loaded\n",
    "if not openai_api_key or not hf_token:\n",
    "    raise ValueError(\"Missing API keys. Ensure OPENAI_API_KEY and HF_TOKEN are set in the .env file.\")\n",
    "\n",
    "# Set environment variables explicitly (optional)\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "\n",
    "# Log in to Hugging Face\n",
    "login(hf_token, add_to_git_credential=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading and Exploring the Dataset**\n",
    "#### **1. Loading the Home Appliances Dataset**\n",
    "We will load the dataset **specific to home appliances** from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for Home Appliances\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Appliances\", split=\"full\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Checking the Dataset Size**\n",
    "To understand the dataset scale, let's check how many data points we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Appliances: {len(dataset):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate a particular datapoint\n",
    "datapoint = dataset[2]\n",
    "datapoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Understanding the Data Structure**\n",
    "Each data point in the dataset contains multiple attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate: Print key attributes\n",
    "\n",
    "print(datapoint[\"title\"])       # Product title\n",
    "print(datapoint[\"description\"]) # Product description\n",
    "print(datapoint[\"features\"])    # Product features\n",
    "print(datapoint[\"details\"])     # Additional details\n",
    "print(datapoint[\"price\"])       # Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning and Filtering**\n",
    "To ensure high-quality data for training, we need to **filter and clean the dataset**.\n",
    "\n",
    "#### **1. Checking How Many Items Have Prices**\n",
    "Many product entries might be missing price information. We count how many have valid prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many have prices?\n",
    "\n",
    "prices = 0\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            prices += 1\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "print(f\"There are {prices:,} with prices which is {prices/len(dataset)*100:,.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Filtering Items with Valid Prices**\n",
    "We only select **products with valid prices** between **$1 and $999**, ensuring a **reasonable price range**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those with prices, gather the price and the length\n",
    "\n",
    "valid_prices = []\n",
    "lengths = []\n",
    "\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if 1 <= price <= 999:\n",
    "            valid_prices.append(price)\n",
    "            content = datapoint[\"title\"] + str(datapoint[\"description\"]) + str(datapoint[\"features\"]) + str(datapoint[\"details\"])\n",
    "            lengths.append(len(content))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Data Distributions**\n",
    "#### **1. Distribution of Text Lengths**\n",
    "We analyze the **length of product descriptions** to ensure they contain meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Lengths: Avg {sum(lengths)/len(lengths):,.0f} and highest {max(lengths):,}\\n\")\n",
    "plt.xlabel('Length (chars)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(lengths, rwidth=0.7, color=\"lightblue\", bins=range(0, 6000, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Distribution of Prices**\n",
    "To understand price variations, we plot a histogram of **price values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(valid_prices)/len(valid_prices):,.2f} and highest {max(valid_prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(valid_prices, rwidth=0.7, color=\"orange\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's printout this outpier item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what is this item??\n",
    "\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 21000:\n",
    "            print(datapoint['title'])\n",
    "    except ValueError as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing Data for Training**\n",
    "#### **1. Creating Structured Data with the `Item` Class**\n",
    "We use an `Item` class to **process and format** data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.items import Item\n",
    "\n",
    "# Create Item objects for products with valid prices\n",
    "items = []\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if 1 <= price <= 999:\n",
    "            item = Item(datapoint, price)\n",
    "            if item.include:\n",
    "                items.append(item)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "print(f\"There are {len(items):,} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Understanding Tokenization Constraints**\n",
    "We **truncate product descriptions** to **160 tokens** to fit within model input limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first item\n",
    "\n",
    "items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the prompt that will be used during training - the model learns to complete this\n",
    "\n",
    "print(items[1].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the prompt that will be used during testing - the model has to complete this\n",
    "\n",
    "print(items[1].test_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Let's plot the distribution of token counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of token counts\n",
    "\n",
    "tokens = [item.token_count for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
    "plt.xlabel('Length (tokens)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(tokens, rwidth=0.7, color=\"green\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Let's plot the distribution of prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "prices = [item.price for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"purple\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Why 180 Tokens?**\n",
    "- **Balance of detail & efficiency** â€“ enough context to predict price while keeping training efficient.  \n",
    "- **Matches real-world usage** â€“ At inference time, product descriptions will be short.  \n",
    "- **Trial & error** â€“ We found that **180 tokens** produced **optimal results**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Coming Up Next**\n",
    "- **Merging with other categories** â€“ We will combine Electronics, Automotive, etc.  \n",
    "- **Building the final dataset** â€“ Selecting **high-quality** samples for model training  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
